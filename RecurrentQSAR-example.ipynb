{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import r2_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data_preprocessing as dp\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = './data/jak2_data.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import read_smiles_property_file\n",
    "from data import cross_validation_split\n",
    "from data import PredictorData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_data = PredictorData(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = ['<', '>', '#', '%', ')', '(', '+', '-', '/', '.', '1', '0', '3', '2', '5', '4', '7',\n",
    "          '6', '9', '8', '=', 'A', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'P', 'S', '[', ']',\n",
    "          '\\\\', 'c', 'e', 'i', 'l', 'o', 'n', 'p', 's', 'r', ' ']\n",
    "char2idx = {}\n",
    "my_data.load_dictionary(tokens, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = []\n",
    "for sm in my_data.smiles:\n",
    "    lens.append(len(sm))\n",
    "max_len = max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(my_data.smiles)):\n",
    "    l = len(my_data.smiles[i])\n",
    "    my_data.smiles[i] = my_data.smiles[i] + ' '*(max_len - l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_val_data, cross_val_labels = cross_validation_split(my_data.smiles, my_data.property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_char_tensor(smiles, use_cuda):\n",
    "    tensor = torch.zeros(len(smiles), len(smiles[0])).long()\n",
    "    for i in range (len(smiles)):\n",
    "        string = smiles[i]\n",
    "        for c in range(len(string)):\n",
    "            tensor[i, c] = self.all_characters.index(string[c])\n",
    "    if use_cuda:\n",
    "        return Variable(tensor.cuda())\n",
    "    else:\n",
    "        return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize=100):\n",
    "    n = X.shape[0]\n",
    "    ind = np.random.permutation(n)\n",
    "    for start_index in range(0, n, batchsize):\n",
    "        X_batch = batch_char_tensor(X[ind[start_index:start_index + batchsize]])\n",
    "        y_batch = y[ind[start_index:start_index + batchsize], :]\n",
    "        if use_cuda:\n",
    "            yield (X_batch, torch.from_numpy(y_batch).float().cuda())\n",
    "        else:\n",
    "            yield (X_batch, torch.from_numpy(y_batch).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES based QSAR with Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from RecurrentQSAR import RecurrentQSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "train_logs = []\n",
    "val_logs = []\n",
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "    \n",
    "    models.append(RecurrentQSAR(input_dim=my_data.n_characters, data=my_data))\n",
    "    models[i].cuda()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adadelta(models[i].parameters(), lr=0.1,  weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    \n",
    "    trX = np.concatenate(cross_val_data[:i] + cross_val_data[i+1:])\n",
    "    trY = np.concatenate(cross_val_labels[:i] + cross_val_labels[i+1:])\n",
    "    teX = np.array(cross_val_data[i])\n",
    "    teY = np.array(cross_val_labels[i])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        models[i].fit(criterion, optimizer, trX, trY.reshape(-1), train_loss_log, num_epochs=1, batch_size=batch_size)\n",
    "        models[i].validate(teX, teY, batch_size = batch_size, val_loss_log=val_loss_log)\n",
    "        \n",
    "    train_logs.append(train_loss_log)\n",
    "    val_logs.append(val_loss_log)\n",
    "    plt.plot(train_loss_log)\n",
    "    plt.plot(val_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python_env_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
